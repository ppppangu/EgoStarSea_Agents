"""å¯¹å¤–æä¾›æœåŠ¡çš„ä¸»ç¨‹åº"""
# æœåŠ¡æ¡†æ¶
from loguru import logger
import uuid
from datetime import datetime
from typing import Dict, List, Optional, Any, Type, Literal
import json
import aiofiles
import httpx
import yaml
import pathlib
import pytz
import chardet
import re
import traceback
import aiohttp
import asyncpg
from pydantic import BaseModel
from jinja2 import Template
import threading
import queue
import jinja2
from boto3 import client
from starlette.applications import Starlette
from starlette.responses import JSONResponse
from starlette.routing import Route
from starlette.requests import Request
from starlette.middleware import Middleware
from starlette.middleware.cors import CORSMiddleware
from starlette.responses import StreamingResponse
from datetime import datetime
from dataclasses import dataclass
import asyncio # ç¡®ä¿ asyncio è¢«å¯¼å…¥
import base64  # å¤„ç†ä¸Šä¼ å›¾ç‰‡çš„ base64 ç¼–ç 
from starlette.datastructures import UploadFile  # ç±»å‹åˆ¤æ–­

# MCPç›¸å…³å¯¼å…¥
from mcp.client.sse import sse_client
from mcp.client.session import ClientSession
from mcp.types import TextContent, CreateMessageRequestParams, CreateMessageResult
from mcp.shared.context import RequestContext
from mcp.server.fastmcp.prompts import base

# å¯¼å…¥Rediså¯¹è¯ç®¡ç†å™¨
from preserve_library.conversation_manager.redis_base import ConversationRedisManager

# å¯¼å…¥åŠŸèƒ½å‡½æ•°
from sub_mcp_server import LOGS_DIR
# from sub_mcp_server.human_sample_server import sampling_callback  # æˆ‘ä»¬å°†åœ¨è¿™é‡Œé‡æ–°å®šä¹‰
from preserve_library.config_reader import read_yaml_config, read_yaml_sse, read_yaml_api
from preserve_library.conversation_manager.redis_base import convert_messages

# å¯¼å…¥å•ä¾‹æ¨¡å¼
from singleton_mode.singleton_fastchat_llm import get_latest_fastchat_llm_instance
from singleton_mode.singleton_model import get_specific_model_instance

# å…¨å±€äººç±»é‡‡æ ·å­˜å‚¨
human_sampling_requests = {}  # å­˜å‚¨å¾…å¤„ç†çš„é‡‡æ ·è¯·æ±‚
human_sampling_responses = {}  # å­˜å‚¨ç”¨æˆ·çš„å“åº”

# å¯¼å…¥å·¥å…·ç®¡ç†æ¨¡å—
from preserve_library.custom_tools.self_tools import get_all_tool_list, get_select_tool_list, update_select_tool_list

# ç»“æœæ¨¡æ¿
# ä¸ºäº†ç¡®ä¿ "params" å­—æ®µä¸­çš„å†…å®¹å§‹ç»ˆæ˜¯åˆæ³• JSON å­—ç¬¦ä¸²ï¼Œ
# è¿™é‡Œä½¿ç”¨é¢„å…ˆç»è¿‡ä¸¤æ¬¡ json.dumps å¤„ç†åçš„ `tool_call_json_escaped` å˜é‡ã€‚
# è¯¥å˜é‡æœ¬èº«åŒ…å«å¤–å±‚å¼•å·ä»¥åŠå†…éƒ¨å·²è½¬ä¹‰çš„åŒå¼•å·ï¼Œå¯ç›´æ¥ä½œä¸º JSON å­—ç¬¦ä¸²å€¼æ’å…¥ã€‚
tool_result_template = jinja2.Template("""
{% if is_error %}
```json
{
"params": {{ tool_call_json_escaped }},
"tool_response":"Tool execution for {{ tool_call['tool'] }} returned None",
"is_error":"true"
}
```
{% else %}
```json
{
"params": {{ tool_call_json_escaped }},
"tool_response":"{{ result }}",
"is_error":"false"
}
```
{% endif %}
""")

# æ–°çš„æ”¯æŒç½‘ç»œè¾“å…¥çš„é‡‡æ ·å›è°ƒå‡½æ•°
async def sampling_callback(context, params):
    """æ”¯æŒç½‘ç»œè¾“å…¥çš„äººç±»é‡‡æ ·å›è°ƒå‡½æ•°"""
    import re
    import uuid
    import time
    from mcp.types import TextContent, CreateMessageResult

    # æå–ç”¨æˆ·æ–‡æœ¬
    last_content = params.messages[-1].content
    if isinstance(last_content, TextContent):
        user_text = last_content.text
    else:
        user_text = str(last_content)

    # è§£æé—®é¢˜å’Œé€‰é¡¹
    question_match = re.search(r'å…³äºé—®é¢˜:\s*(.+?),\s*è¯·é€‰æ‹©ä»¥ä¸‹é€‰é¡¹:', user_text)
    options_match = re.search(r'è¯·é€‰æ‹©ä»¥ä¸‹é€‰é¡¹:\s*(\[.*?\])', user_text)

    question = question_match.group(1) if question_match else user_text
    options = []

    if options_match:
        try:
            import ast
            options = ast.literal_eval(options_match.group(1))
        except:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç®€å•çš„å­—ç¬¦ä¸²åˆ†å‰²
            options_str = options_match.group(1).strip('[]')
            options = [opt.strip().strip("'\"") for opt in options_str.split(',')]

    # ç”Ÿæˆå”¯ä¸€çš„è¯·æ±‚ID
    request_id = str(uuid.uuid4())

    # å­˜å‚¨è¯·æ±‚åˆ°å…¨å±€å­—å…¸
    human_sampling_requests[request_id] = {
        "question": question,
        "options": options,
        "timestamp": time.time()
    }

    # æ‰“å°æç¤ºä¿¡æ¯
    print(f"\n================ äººå·¥é‡‡æ · ================")
    print(f"é—®é¢˜: {question}")
    print(f"é€‰é¡¹: {options}")
    print(f"è¯·æ±‚ID: {request_id}")
    print(f"è¯·è®¿é—® http://localhost:8086/v1/human-sampling è¿›è¡Œç½‘ç»œè¾“å…¥")
    print(f"æˆ–ç­‰å¾…ç½‘ç»œå“åº”...")
    print("=" * 50)

    # ç­‰å¾…ç”¨æˆ·å“åº”ï¼ˆè½®è¯¢æ£€æŸ¥ï¼‰
    timeout = 300  # 5åˆ†é’Ÿè¶…æ—¶
    start_time = time.time()

    while time.time() - start_time < timeout:
        if request_id in human_sampling_responses:
            answer = human_sampling_responses[request_id]
            # æ¸…ç†å“åº”
            del human_sampling_responses[request_id]
            print(f"æ”¶åˆ°ç”¨æˆ·å“åº”: {answer}")

            return CreateMessageResult(
                role="user",
                content=TextContent(type="text", text=str(answer)),
                model="human-input",
                stopReason="endTurn",
            )

        # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
        await asyncio.sleep(1)

    # è¶…æ—¶å¤„ç†
    if request_id in human_sampling_requests:
        del human_sampling_requests[request_id]

    print("äººç±»é‡‡æ ·è¶…æ—¶ï¼Œä½¿ç”¨é»˜è®¤å“åº”")
    return CreateMessageResult(
        role="user",
        content=TextContent(type="text", text="è¶…æ—¶ï¼Œè·³è¿‡æ­¤é—®é¢˜"),
        model="human-input",
        stopReason="endTurn",
    )

# è¯·æ±‚æ¨¡å‹
from typing import Union, Dict, Any, List

# å®šä¹‰å¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹ç±»å‹
class ImageUrl(BaseModel):
    url: str

class TextContent(BaseModel):
    type: Literal["text"] = "text"
    text: str

class ImageUrlContent(BaseModel):
    type: Literal["image_url"] = "image_url"
    image_url: Union[ImageUrl, str]

# æ¶ˆæ¯å†…å®¹å¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å†…å®¹é¡¹åˆ—è¡¨
ContentItem = Union[TextContent, ImageUrlContent]
MessageContent = Union[str, List[ContentItem], List[Dict[str, Any]]]

class ChatMessage(BaseModel):
    role: str
    content: MessageContent

class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹ - OpenAIå…¼å®¹æ ¼å¼"""
    user_id: str  # æ ¼å¼ä¸º 'user_id@session_id'
    model: Optional[str] = None
    messages: List[Union[ChatMessage, Dict[str, Any]]]
    single_hint: Optional[bool] = False
    class Config:
        arbitrary_types_allowed = True

    def get_messages_as_dict(self) -> List[Dict[str, Any]]:
        """å°†æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨"""
        result = []
        for msg in self.messages:
            if hasattr(msg, "model_dump"):
                result.append(msg.model_dump())
            else:
                result.append(msg)
        return result

class PromptListRequest(BaseModel):
    """è·å–æç¤ºæ¨¡æ¿åˆ—è¡¨è¯·æ±‚"""
    pass

class PromptGetRequest(BaseModel):
    """è·å–ç‰¹å®šæç¤ºæ¨¡æ¿è¯·æ±‚"""
    prompt_id: str
    parameters: Optional[Dict[str, Any]] = {}

# å“åº”æ¨¡å‹
class ChatResponse(BaseModel):
    """èŠå¤©å“åº”æ¨¡å‹ - OpenAIå…¼å®¹æ ¼å¼"""
    id: str
    object: str = "chat.completion"
    created: int
    model: str
    choices: List[Dict[str, Any]]
    usage: Dict[str, int]

class PromptListResponse(BaseModel):
    """æç¤ºæ¨¡æ¿åˆ—è¡¨å“åº”"""
    prompts: List[Dict[str, Any]]

class PromptGetResponse(BaseModel):
    """ç‰¹å®šæç¤ºæ¨¡æ¿å“åº”"""
    prompt_id: str
    content: str
    parameters: Dict[str, Any]

@dataclass
class Model:
    id: str
    object: str
    created: int
    owned_by: str


# åˆå§‹åŒ–Rediså¯¹è¯ç®¡ç†å™¨
redis_config = read_yaml_config().get("redis", {})
conversation_manager = ConversationRedisManager(
    host=redis_config.get("host", "localhost"),
    port=redis_config.get("port", 6379),
    db=redis_config.get("db", 0)
)
# æ–¹ä¾¿å‰ç«¯å±•ç¤ºçš„å¯¹è¯å†å²è®°å½•å™¨ï¼Œæ‰€æœ‰çš„å‡ä¸€è‡´ï¼Œåªæ˜¯æ–¹ä¾¿äº†å‰ç«¯ç›´æ¥è¯»å–æ•°æ®åº“æ—¶çš„æŸ¥è¯¢ï¼Œä¸æ€ä¹ˆéœ€è¦ä¿®æ”¹
frontend_conversation_manager = ConversationRedisManager(
    host=redis_config.get("host", "localhost"),
    port=redis_config.get("port", 6379),
    db=redis_config.get("frontend_db", 1)
)

# LLMå®¢æˆ·ç«¯
class LLMClient:
    """ç®¡ç†ä¸LLMçš„é€šä¿¡"""
    def __init__(
        self,
        api_key: Optional[str] = None,
        api_url: Optional[str] = None,
        model_name: Optional[str] = None,
        use_singleton: bool = False,
    ) -> None:
        # å¯¼å…¥é…ç½®è¯»å–æ¨¡å—
        from preserve_library.config_reader import get_model_config

        # å¦‚æœæä¾›äº†æ¨¡å‹åç§°ï¼Œä½¿ç”¨é…ç½®è¯»å–æ¨¡å—è·å–é…ç½®
        if model_name:
            try:
                config = get_model_config(model_name, use_singleton)
                if config:
                    _, config_url, config_key = config
                    self.model_name = model_name
                    self.api_url = api_url or config_url
                    self.api_key = api_key or config_key
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°é…ç½®ï¼Œä½¿ç”¨ä¼ å…¥çš„å€¼
                    self.model_name = model_name
                    self.api_url = api_url or ""
                    self.api_key = api_key or ""
                    logger.warning(f"æ— æ³•æ‰¾åˆ°æ¨¡å‹ {model_name} çš„é…ç½®ï¼Œä½¿ç”¨ä¼ å…¥å‚æ•°")
            except Exception as e:
                logger.warning(f"è¯»å–æ¨¡å‹é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨ä¼ å…¥å‚æ•°")
                self.model_name = model_name
                self.api_url = api_url or ""
                self.api_key = api_key or ""
        else:
            # å¦‚æœæ²¡æœ‰æä¾›æ¨¡å‹åç§°ï¼Œå°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–é»˜è®¤å€¼
            llm_conf = {}
            try:
                llm_configs = read_yaml_api("language_llm")
                if llm_configs:
                    llm_conf = llm_configs[0]
            except Exception as e:
                logger.warning(f"è¯»å–LLMé…ç½®å¤±è´¥: {e}")

            # ä½¿ç”¨æä¾›çš„å€¼æˆ–é»˜è®¤å€¼
            self.api_key = api_key or llm_conf.get("key", "")
            self.api_url = api_url or llm_conf.get("url", "")
            self.model_name = model_name or llm_conf.get("name", "")

        self._client = httpx.AsyncClient(timeout=60.0)


    async def get_response(self, messages: list[dict[str, str | list[dict[str, str]]]], stream: bool = False, max_tokens: int = 8000) -> str:
        """è·å–LLMå“åº”"""
        # è·å–å½“å‰æ¨¡å‹çš„é…ç½®ï¼Œæ”¯æŒè´Ÿè½½å‡è¡¡
        model_name, api_url, api_key = await asyncio.to_thread(get_specific_model_instance, self.model_name)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }
        payload = {
            "messages": messages,
            "model": model_name,
            "temperature": 0.7,
            "max_tokens": max_tokens,
            "top_p": 1,
            "stream": stream,
        }

        try:
            response = await self._client.post(
                api_url,
                headers=headers,
                json=payload
            )
            response.raise_for_status()
            data = response.json()
            return data["choices"][0]["message"]["content"]
        except Exception as e:
            logger.error(f"LLMè¯·æ±‚å¤±è´¥: {str(e)}")
            return f"LLMè¯·æ±‚å¤±è´¥: {str(e)}"

    async def stream_response(self, messages: list[dict[str, str | list[dict[str, str]]]], max_tokens: int = 8000):
        """ä»¥ SSE æµå¼æ–¹å¼è·å– LLM å“åº”ã€‚

        Yields é€è¡Œå­—ç¬¦ä¸²ï¼Œä¿æŒä¸ä¸Šæ¸¸ LLM çš„ `data:` åè®®ä¸€è‡´ï¼Œäº¤ç”±ä¸Šå±‚è§£æã€‚
        """

        model_name, api_url, api_key = await asyncio.to_thread(get_specific_model_instance, self.model_name)

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }
        payload = {
            "messages": messages,
            "model": model_name,
            "temperature": 0.7,
            "max_tokens": max_tokens,
            "top_p": 1,
            "stream": True,
        }

        try:
            logger.debug(f"å‘é€LLMè¯·æ±‚åˆ°: {api_url}")
            logger.debug(f"è¯·æ±‚å¤´: {headers}")
            logger.debug(f"è¯·æ±‚ä½“: {json.dumps(payload, ensure_ascii=False)}")

            async with self._client.stream("POST", api_url, headers=headers, json=payload) as response:
                logger.debug(f"æ”¶åˆ°å“åº”çŠ¶æ€ç : {response.status_code}")
                response.raise_for_status()
                async for line in response.aiter_lines():
                    if not line:
                        continue
                    # logger.debug(f"æ”¶åˆ°æµå¼å“åº”è¡Œ: {line}")
                    yield line
        except httpx.HTTPStatusError as e:
            error_msg = f"LLM APIè¿”å›é”™è¯¯çŠ¶æ€ç  {e.response.status_code}: {e.response.text}"
            logger.error(error_msg)
            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œå‘ä¸Šæ¸¸å‘é€ä¸€ä¸ªç‰¹æ®Šæ ‡è®°ï¼Œä¾¿äºå‰ç«¯è¯†åˆ«
            yield f"data: [ERROR] {error_msg}"
        except Exception as e:
            logger.error(f"LLMæµå¼è¯·æ±‚å¤±è´¥: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œå‘ä¸Šæ¸¸å‘é€ä¸€ä¸ªç‰¹æ®Šæ ‡è®°ï¼Œä¾¿äºå‰ç«¯è¯†åˆ«
            yield f"data: [ERROR] {str(e)}"

class ChatSession:
    """ç®¡ç†ä¸€æ¬¡è¿æ¥ä¸å•ä¸ª MCP SSE æœåŠ¡å™¨çš„è¿æ¥"""

    def __init__(self, sse_server: str, llm_client: LLMClient) -> None:
        self.sse_server: str = sse_server
        self.llm_client: LLMClient = llm_client
        self.session: ClientSession | None = None
        self.tools: List[Any] = []  # ç¼“å­˜å·¥å…·åˆ—è¡¨

    async def process_llm_response(self, llm_response: str) -> tuple[str, bool]:
        """Process the LLM response and execute tools if needed.

        Args:
            llm_response: The response from the LLM.

        Returns:
            Tuple of (result, tool_use_bool): The result of tool execution or the original response, and whether tools were used.
        """
        import re
        
        logger.info(f"å¼€å§‹å¤„ç†LLMå“åº”ï¼Œå†…å®¹é•¿åº¦: {len(llm_response)}")
        
        # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•ä»Markdownä»£ç å—ä¸­æå–JSON
        # åŒ¹é… ```json\n...``` æˆ– ```\n{...}\n``` æ ¼å¼
        # å¦‚æœåŒ¹é…åˆ°ï¼Œåˆ™è®¤ä¸ºä½¿ç”¨äº†å·¥å…·,å°†tool_use_boolè®¾ç½®ä¸ºTrue, å¦åˆ™è®¤ä¸ºæ²¡æœ‰ä½¿ç”¨å·¥å…·,å°†tool_use_boolè®¾ç½®ä¸ºFalse
        tool_use_bool = False
        
        # æ›´ä¸¥æ ¼çš„æ­£åˆ™è¡¨è¾¾å¼ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„å·¥å…·è°ƒç”¨æ ¼å¼
        json_pattern = r'```(?:json)?\s*\n(\{.*?"tool"\s*:\s*"[^"]+"\s*,.*?"arguments"\s*:\s*\{.*?\}.*?\})\s*\n```'
        matches = re.findall(json_pattern, llm_response, re.DOTALL | re.IGNORECASE)
        
        logger.info(f"æ‰¾åˆ° {len(matches)} ä¸ªå¯èƒ½çš„å·¥å…·è°ƒç”¨ä»£ç å—")

        needed_tool_call = []

        for i, match in enumerate(matches):
            logger.info(f"æ£€æŸ¥ç¬¬ {i+1} ä¸ªåŒ¹é…é¡¹: {match[:100]}...")
            try:
                tool_call = json.loads(match.strip())
                logger.info(f"æˆåŠŸè§£æJSON: {tool_call}")
                
                # ä¸¥æ ¼éªŒè¯å·¥å…·è°ƒç”¨æ ¼å¼
                if (isinstance(tool_call, dict) and 
                    "tool" in tool_call and 
                    "arguments" in tool_call and
                    isinstance(tool_call["tool"], str) and
                    isinstance(tool_call["arguments"], dict)):
                    
                    logger.info(f"æ£€æµ‹åˆ°æœ‰æ•ˆå·¥å…·è°ƒç”¨: {tool_call['tool']}")
                    needed_tool_call.append(tool_call)
                    tool_use_bool = True
                else:
                    logger.info(f"JSONæ ¼å¼ä¸ç¬¦åˆå·¥å…·è°ƒç”¨è¦æ±‚: {tool_call}")
            except json.JSONDecodeError as e:
                logger.warning(f"JSONè§£æå¤±è´¥: {e}")
                continue

        logger.info(f"æœ‰æ•ˆå·¥å…·è°ƒç”¨æ•°é‡: {len(needed_tool_call)}, tool_use_bool: {tool_use_bool}")

        if len(needed_tool_call) == 0:
            logger.info("æ²¡æœ‰æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œè¿”å›åŸå§‹å“åº”")
            return llm_response, False  # æ˜ç¡®è¿”å›False
        else:
            logger.info(f"å¼€å§‹æ‰§è¡Œ {len(needed_tool_call)} ä¸ªå·¥å…·è°ƒç”¨")
            tool_use_bool = True

            tool_call_tasks = [self._execute_tool_call(tool_call) for tool_call in needed_tool_call]
            results = await asyncio.gather(*tool_call_tasks)
            multi_tool_call_result = ""
            for tool_call, result in zip(needed_tool_call, results):
                if result is not None:
                    # å¤„ç†æ¢è¡Œç¬¦ï¼Œç¡®ä¿ JSON åˆæ³•
                    result_escaped = json.dumps(result, ensure_ascii=False)[1:-1]
                    formatted_result = await asyncio.to_thread(
                        tool_result_template.render,
                        tool_call=tool_call,
                        tool_call_json_escaped=json.dumps(json.dumps(tool_call, ensure_ascii=False), ensure_ascii=False),
                        result=result_escaped,
                        is_error=False
                    )
                    formatted_result_text = str(formatted_result)
                    multi_tool_call_result = multi_tool_call_result + "\n\n" + formatted_result_text + "\n\n"
                else:
                    formatted_result = await asyncio.to_thread(
                        tool_result_template.render,
                        tool_call=tool_call,
                        tool_call_json_escaped=json.dumps(json.dumps(tool_call, ensure_ascii=False), ensure_ascii=False),
                        result=None,
                        is_error=True
                    )
                    formatted_result_text = str(formatted_result)
                    multi_tool_call_result = multi_tool_call_result+ "\n\n" + formatted_result_text + "\n\n"
            
            logger.info(f"å·¥å…·æ‰§è¡Œå®Œæˆï¼Œç»“æœé•¿åº¦: {len(multi_tool_call_result)}")
            return multi_tool_call_result, True

    async def _execute_tool_call(self, tool_call: dict) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨çš„å…·ä½“é€»è¾‘"""

        logger.info(f"Executing tool: {tool_call['tool']}")
        logger.info(f"With arguments: {tool_call['arguments']}")
        tool_name = tool_call["tool"]

        if not self.session:
            return "Session not initialized"

        # æŸ¥æ‰¾æœ¬åœ°ç¼“å­˜çš„å·¥å…·åˆ—è¡¨
        if any(tool.name == tool_call["tool"] for tool in self.tools):
            try:
                # è¯»å–MCPè¶…æ—¶é…ç½®
                config = read_yaml_config()
                tool_call_timeout = config.get("mcp", {}).get("timeout", {}).get("tool_call", 1200)  # é»˜è®¤20åˆ†é’Ÿ

                # å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
                complex_tools = ["generate_artifact", "execute_code", "websearch_tavily", "sequential_thinking"]
                if tool_call["tool"] in complex_tools:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å¤æ‚ä»»åŠ¡
                    args = tool_call["arguments"]
                    is_complex = False

                    # æ£€æŸ¥ä»»åŠ¡æè¿°ä¸­æ˜¯å¦åŒ…å«å¤æ‚ä»»åŠ¡å…³é”®è¯
                    for key, value in args.items():
                        if isinstance(value, str) and any(keyword in value.lower() for keyword in
                                                        ['ppt', 'presentation', 'é¡µ', 'page', 'ç« èŠ‚', 'chapter', 'åŸ¹è®­', 'å¤æ‚', 'è¯¦ç»†']):
                            is_complex = True
                            break

                    if is_complex:
                        tool_call_timeout = max(tool_call_timeout, 1800)  # è‡³å°‘30åˆ†é’Ÿ
                        logger.info(f"æ£€æµ‹åˆ°å¤æ‚ä»»åŠ¡ï¼Œè®¾ç½®å·¥å…·è°ƒç”¨è¶…æ—¶ä¸º{tool_call_timeout}ç§’")

                # ä½¿ç”¨asyncio.wait_foræ·»åŠ è¶…æ—¶æ§åˆ¶
                call_result = await asyncio.wait_for(
                    self.session.call_tool(tool_call["tool"], tool_call["arguments"]),
                    timeout=tool_call_timeout
                )

                if call_result.isError:
                    return f"Error executing tool: {call_result.content}"

                # å¤„ç†è¿”å›çš„ content
                try:
                    # å°è¯•å°†å†…å®¹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    if isinstance(call_result.content, list):
                        # å¤„ç†åˆ—è¡¨ç±»å‹çš„å†…å®¹
                        contents = []
                        for c in call_result.content:
                            if hasattr(c, "text"):
                                contents.append(c.text)
                            elif isinstance(c, dict):
                                # å¤„ç†å­—å…¸ç±»å‹ï¼Œç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²éƒ½æ˜¯æœ‰æ•ˆçš„UTF-8
                                sanitized_dict = {}
                                for key, value in c.items():
                                    if isinstance(value, str):
                                        # ä½¿ç”¨æ›´å¼ºå¤§çš„ç¼–ç å¤„ç†
                                        try:
                                            detected = chardet.detect(value.encode('utf-8', errors='ignore'))
                                            if detected['encoding'] and detected['encoding'].lower() != 'utf-8':
                                                # å°è¯•ä½¿ç”¨æ£€æµ‹åˆ°çš„ç¼–ç è¿›è¡Œè§£ç ï¼Œç„¶åé‡æ–°ç¼–ç ä¸ºUTF-8
                                                try:
                                                    value = value.encode(detected['encoding'], errors='ignore').decode(detected['encoding']).encode('utf-8').decode('utf-8')
                                                    logger.info(f"å·²å°†å€¼ä» {detected['encoding']} è½¬æ¢ä¸º UTF-8")
                                                except Exception as enc_err:
                                                    logger.warning(f"ç¼–ç è½¬æ¢å¤±è´¥: {str(enc_err)}ï¼Œä½¿ç”¨åŸå§‹å€¼")
                                        except ImportError:
                                            # å¦‚æœæ²¡æœ‰chardetï¼Œå›é€€åˆ°ç®€å•çš„ç¼–ç å¤„ç†
                                            pass

                                        sanitized_value = value.encode('utf-8', errors='replace').decode('utf-8')
                                        sanitized_dict[key] = sanitized_value
                                    else:
                                        sanitized_dict[key] = value
                                # ä½¿ç”¨JSONåºåˆ—åŒ–ç¡®ä¿ç»“æœæ˜¯æœ‰æ•ˆçš„UTF-8
                                try:
                                    contents.append(json.dumps(sanitized_dict, ensure_ascii=False))
                                except:
                                    contents.append(str(sanitized_dict))
                            else:
                                # å…¶ä»–ç±»å‹ç›´æ¥è½¬ä¸ºå­—ç¬¦ä¸²
                                contents.append(str(c))

                        contents_str = "\n".join(contents)
                    else:
                        # éåˆ—è¡¨ç±»å‹ç›´æ¥è½¬ä¸ºå­—ç¬¦ä¸²
                        contents_str = str(call_result.content)

                    return f"Tool execution result:ã€{tool_name}ã€‘ {contents_str}\n\n"
                except Exception as e:
                    logger.error(f"å¤„ç†å·¥å…·æ‰§è¡Œç»“æœæ—¶å‡ºé”™: {str(e)}")
                    return f"Tool execution result:ã€{tool_name}ã€‘ [å¤„ç†ç»“æœæ—¶å‡ºé”™ï¼Œä½†å·¥å…·å·²æˆåŠŸæ‰§è¡Œ]"
            except asyncio.TimeoutError:
                timeout_msg = f"å·¥å…·è°ƒç”¨è¶…æ—¶: {tool_name}ï¼Œè¶…æ—¶æ—¶é—´: {tool_call_timeout}ç§’ã€‚å»ºè®®ï¼š1)ç®€åŒ–ä»»åŠ¡ 2)åˆ†æ­¥æ‰§è¡Œ 3)ç¨åé‡è¯•"
                logger.error(timeout_msg)
                return timeout_msg
            except Exception as e:
                error_msg = f"Error executing tool: {str(e)}"
                logger.error(error_msg)
                return error_msg

        return f"No tool found: {tool_name}"

# ç‰¹å®šå·¥å…·ä½¿ç”¨çš„æš—å·
tool_secret_dict = {
    "classify_sample": "classify_sample"
}

# å·¥å…·ä½¿ç”¨åˆ¤æ–­å‡½æ•°
async def tool_need_check(messages: list):
    if isinstance(messages[0]["content"], list):
        return True
    return False

# äººç±»é‡‡æ ·ç›¸å…³è·¯ç”±å¤„ç†å‡½æ•°
async def get_pending_samples(request: Request):
    """è·å–å¾…å¤„ç†çš„äººç±»é‡‡æ ·è¯·æ±‚"""
    return JSONResponse({
        "pending_requests": list(human_sampling_requests.keys()),
        "requests": human_sampling_requests
    })

async def submit_sample_response(request: Request):
    """æäº¤äººç±»é‡‡æ ·å“åº”"""
    try:
        data = await request.json()
        request_id = data.get("request_id")
        response = data.get("response")

        if not request_id or response is None:
            return JSONResponse(
                {"error": "ç¼ºå°‘ request_id æˆ– response å‚æ•°"},
                status_code=400
            )

        if request_id not in human_sampling_requests:
            return JSONResponse(
                {"error": "é‡‡æ ·è¯·æ±‚ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ"},
                status_code=404
            )

        # å­˜å‚¨å“åº”
        human_sampling_responses[request_id] = response

        # æ¸…ç†è¯·æ±‚
        del human_sampling_requests[request_id]

        return JSONResponse({
            "success": True,
            "message": "å“åº”å·²æäº¤"
        })

    except Exception as e:
        return JSONResponse(
            {"error": f"å¤„ç†å“åº”æ—¶å‡ºé”™: {str(e)}"},
            status_code=500
        )

async def get_sample_interface(request: Request):
    """è·å–äººç±»é‡‡æ ·çš„Webç•Œé¢"""
    html_content = """
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>äººç±»é‡‡æ ·ç•Œé¢</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }
            .container { max-width: 800px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
            .request-item { border: 1px solid #ddd; margin: 10px 0; padding: 15px; border-radius: 5px; background: #f9f9f9; }
            .question { font-weight: bold; color: #333; margin-bottom: 10px; }
            .options { margin: 10px 0; }
            .option-btn { margin: 5px; padding: 8px 15px; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }
            .option-btn:hover { background: #0056b3; }
            .custom-input { width: 100%; padding: 8px; margin: 10px 0; border: 1px solid #ddd; border-radius: 4px; }
            .submit-btn { background: #28a745; color: white; padding: 10px 20px; border: none; border-radius: 4px; cursor: pointer; }
            .submit-btn:hover { background: #218838; }
            .no-requests { text-align: center; color: #666; padding: 40px; }
            .refresh-btn { background: #17a2b8; color: white; padding: 8px 16px; border: none; border-radius: 4px; cursor: pointer; margin-bottom: 20px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ¤– äººç±»é‡‡æ ·ç•Œé¢</h1>
            <button class="refresh-btn" onclick="loadRequests()">ğŸ”„ åˆ·æ–°è¯·æ±‚</button>
            <div id="requests-container">
                <div class="no-requests">æ­£åœ¨åŠ è½½é‡‡æ ·è¯·æ±‚...</div>
            </div>
        </div>

        <script>
            async function loadRequests() {
                try {
                    const response = await fetch('/v1/human-sampling/pending');
                    const data = await response.json();

                    const container = document.getElementById('requests-container');

                    if (Object.keys(data.requests).length === 0) {
                        container.innerHTML = '<div class="no-requests">æš‚æ— å¾…å¤„ç†çš„é‡‡æ ·è¯·æ±‚</div>';
                        return;
                    }

                    container.innerHTML = '';

                    for (const [requestId, requestData] of Object.entries(data.requests)) {
                        const requestDiv = document.createElement('div');
                        requestDiv.className = 'request-item';
                        requestDiv.innerHTML = `
                            <div class="question">${requestData.question}</div>
                            <div class="options">
                                ${requestData.options ? requestData.options.map(option =>
                                    `<button class="option-btn" onclick="submitResponse('${requestId}', '${option}')">${option}</button>`
                                ).join('') : ''}
                            </div>
                            <input type="text" class="custom-input" id="custom-${requestId}" placeholder="æˆ–è¾“å…¥è‡ªå®šä¹‰ç­”æ¡ˆ...">
                            <button class="submit-btn" onclick="submitCustomResponse('${requestId}')">æäº¤è‡ªå®šä¹‰ç­”æ¡ˆ</button>
                        `;
                        container.appendChild(requestDiv);
                    }
                } catch (error) {
                    console.error('åŠ è½½è¯·æ±‚å¤±è´¥:', error);
                    document.getElementById('requests-container').innerHTML =
                        '<div class="no-requests">åŠ è½½å¤±è´¥ï¼Œè¯·åˆ·æ–°é‡è¯•</div>';
                }
            }

            async function submitResponse(requestId, response) {
                try {
                    const result = await fetch('/v1/human-sampling/respond', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ request_id: requestId, response: response })
                    });

                    if (result.ok) {
                        alert('å“åº”å·²æäº¤ï¼');
                        loadRequests();
                    } else {
                        alert('æäº¤å¤±è´¥ï¼Œè¯·é‡è¯•');
                    }
                } catch (error) {
                    alert('æäº¤å¤±è´¥: ' + error.message);
                }
            }

            function submitCustomResponse(requestId) {
                const input = document.getElementById(`custom-${requestId}`);
                const response = input.value.trim();
                if (response) {
                    submitResponse(requestId, response);
                } else {
                    alert('è¯·è¾“å…¥ç­”æ¡ˆ');
                }
            }

            // é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨åŠ è½½è¯·æ±‚
            loadRequests();

            // æ¯5ç§’è‡ªåŠ¨åˆ·æ–°
            setInterval(loadRequests, 5000);
        </script>
    </body>
    </html>
    """

    from starlette.responses import HTMLResponse
    return HTMLResponse(html_content)

# è·¯ç”±å¤„ç†å‡½æ•°
async def chat(request: Request):
    """
    å¤šè½®å¯¹è¯æ¥å£ - OpenAIå…¼å®¹æ ¼å¼
    :method POST
    :param user_id: ç”¨æˆ·IDå’Œä¼šè¯IDçš„ç»„åˆï¼Œæ ¼å¼ä¸º 'user_id@session_id'
    :param model: æ¨¡å‹åç§°
    :param messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªæ¶ˆæ¯åŒ…å«roleå’Œcontentå­—æ®µ
    :return: ChatResponse
    """
    # è§£æè¯·æ±‚æ•°æ®
    # åˆ¤æ–­æ¨¡å‹ç±»å‹ï¼Œå†³å®šåŠ è½½å†å²å¯¹è¯çš„æ¨¡å¼æ¥é€‚é…å¤§æ¨¡å‹å‘é€è¯·æ±‚çš„æ¥å£

    try:
        form_data = await request.form()
        data: Dict[str, Any] = {}
        uploaded_files: Dict[str, str] = {}  # filename -> data:image/...;base64,

        # éå†è¡¨å•å­—æ®µï¼ŒåŒºåˆ†æ–‡æœ¬ä¸æ–‡ä»¶
        for key, value in form_data.items():
            # ---------------- æ–‡ä»¶å­—æ®µ ----------------
            if isinstance(value, UploadFile):
                try:
                    file_bytes = await value.read()
                    mime_type = value.content_type or "application/octet-stream"
                    b64_data = base64.b64encode(file_bytes).decode("utf-8")
                    data_url = f"data:{mime_type};base64,{b64_data}"
                    uploaded_files[value.filename] = data_url
                    logger.info(f"å·²å¤„ç†ä¸Šä¼ æ–‡ä»¶ {value.filename} -> dataURL")
                except Exception as fe:
                    logger.warning(f"è¯»å–ä¸Šä¼ æ–‡ä»¶ {value.filename} å¤±è´¥: {fe}")
                # æ–‡ä»¶å­—æ®µä¸æ”¾å…¥ dataï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                continue

            # ---------------- æ–‡æœ¬å­—æ®µ ----------------
            # ç§»é™¤å¯èƒ½å­˜åœ¨çš„é¢å¤–å¼•å·
            if isinstance(value, str):
                value = value.strip()
                if value.startswith('"') and value.endswith('"'):
                    value = value[1:-1]

            # ç‰¹æ®Šå¤„ç†messageså­—æ®µï¼Œå°è¯•ä½œä¸ºJSONè§£æ
            if key == 'messages':
                try:
                    # å°è¯•è§£æJSON
                    data[key] = json.loads(value)
                    logger.info(f"æˆåŠŸè§£æmessageså­—æ®µ: {data[key]}")

                    # æ£€æŸ¥å¹¶ä¿®å¤å¤šå›¾ç‰‡æ¶ˆæ¯æ ¼å¼
                    for msg in data[key]:
                        if isinstance(msg.get("content"), list):
                            # æ£€æŸ¥contentåˆ—è¡¨ä¸­çš„æ¯ä¸ªé¡¹ç›®
                            fixed_content = []
                            for item in msg["content"]:
                                # æ£€æŸ¥image_urlé¡¹æ˜¯å¦æ ¼å¼æ­£ç¡®
                                if isinstance(item, dict) and item.get("type") == "image_url":
                                    # ç¡®ä¿image_urlæ˜¯å­—å…¸æ ¼å¼
                                    image_url = item.get("image_url")
                                    if isinstance(image_url, dict) and "url" in image_url:
                                        # æ ¼å¼å·²ç»æ­£ç¡®ï¼Œä¸éœ€è¦ä¿®æ”¹
                                        fixed_content.append(item)
                                    elif isinstance(image_url, str):
                                        # å¦‚æœimage_urlæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                                        fixed_content.append({
                                            "type": "image_url",
                                            "image_url": {"url": image_url}
                                        })
                                    elif isinstance(image_url, dict):
                                        # å°è¯•ä»å­—å…¸ä¸­æå–URL
                                        url_value = None
                                        for k, v in image_url.items():
                                            if isinstance(v, str) and (k.lower() == "url" or "url" in k.lower()):
                                                url_value = v
                                                break

                                        if url_value:
                                            fixed_content.append({
                                                "type": "image_url",
                                                "image_url": {"url": url_value}
                                            })
                                        else:
                                            # æ— æ³•ä¿®å¤ï¼Œä¿ç•™åŸæ ·
                                            fixed_content.append(item)
                                    else:
                                        # æ— æ³•è¯†åˆ«çš„æ ¼å¼ï¼Œå°è¯•è½¬æ¢
                                        logger.warning(f"æ— æ³•è¯†åˆ«çš„image_urlæ ¼å¼: {image_url}")
                                        fixed_content.append(item)
                                else:
                                    # éå›¾ç‰‡é¡¹ï¼Œä¿æŒä¸å˜
                                    fixed_content.append(item)

                            # æ›´æ–°æ¶ˆæ¯çš„content
                            msg["content"] = fixed_content
                            logger.info(f"å¤„ç†åçš„æ¶ˆæ¯å†…å®¹: {msg['content']}")
                except json.JSONDecodeError as e:
                    logger.error(f"æ— æ³•è§£æmessageså­—æ®µ: {e}")
                    return JSONResponse(
                        {"error": f"æ— æ³•è§£æmessageså­—æ®µ: {str(e)}"},
                        status_code=400
                    )
            else:
                # å°è¯•è§£æå…¶ä»–å¯èƒ½çš„JSONå­—æ®µ
                try:
                    data[key] = json.loads(value)
                except (json.JSONDecodeError, TypeError):
                    # ä¸æ˜¯JSONï¼Œä¿ç•™åŸå§‹å€¼
                    data[key] = value

        logger.info(f"è¡¨å•æ•°æ®è§£æç»“æœ: {data}")

        # ------------------------------------------------------------------
        # 2ï¸âƒ£ æ ¹æ®ä¸Šä¼ æ–‡ä»¶è¡¥å…¨ / ä¿®æ­£ messages
        # ------------------------------------------------------------------
        if uploaded_files:
            logger.info(f"å…±æ¥æ”¶åˆ° {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œå°†æ³¨å…¥ messages")

            # (a) è‹¥å·²å­˜åœ¨ messagesï¼Œå°è¯•ç”¨æ–‡ä»¶åå ä½ç¬¦æ›¿æ¢ä¸º dataURL
            if "messages" in data:
                used_files = set()
                for msg in data["messages"]:
                    content = msg.get("content")
                    if isinstance(content, list):
                        for item in content:
                            if isinstance(item, dict) and item.get("type") == "image_url":
                                img_obj = item.get("image_url")
                                # image_url å¯èƒ½æ˜¯ str æˆ– dict
                                if isinstance(img_obj, str):
                                    if img_obj in uploaded_files:
                                        item["image_url"] = {"url": uploaded_files[img_obj]}
                                        used_files.add(img_obj)
                                elif isinstance(img_obj, dict) and "url" in img_obj:
                                    url_val = img_obj["url"]
                                    if url_val in uploaded_files:
                                        img_obj["url"] = uploaded_files[url_val]
                                        used_files.add(url_val)

                # å°†å‰©ä½™æœªå¼•ç”¨çš„å›¾ç‰‡è¿½åŠ åˆ°é¦–æ¡æ¶ˆæ¯
                remaining = [v for k, v in uploaded_files.items() if k not in used_files]
                if remaining:
                    if data["messages"]:
                        first_msg = data["messages"][0]
                        if not isinstance(first_msg.get("content"), list):
                            first_msg["content"] = [{"type": "text", "text": str(first_msg.get("content"))}]
                        for u in remaining:
                            first_msg["content"].append({"type": "image_url", "image_url": {"url": u}})
                    else:
                        data["messages"] = [{
                            "role": "user",
                            "content": [{"type": "image_url", "image_url": {"url": u}} for u in remaining]
                        }]

            # (b) è‹¥ messages ä¸å­˜åœ¨ä¸”æœ‰æ–‡ä»¶ï¼Œåˆ™æ ¹æ® query/text å­—æ®µç”Ÿæˆä¸€æ¡æ–°æ¶ˆæ¯
            if "messages" not in data and uploaded_files:
                query_text = data.pop("query", None) or data.pop("text", None) or data.pop("content", "")
                content_items: List[Dict[str, Any]] = []
                if query_text:
                    content_items.append({"type": "text", "text": query_text})
                for url in uploaded_files.values():
                    content_items.append({"type": "image_url", "image_url": {"url": url}})

                data["messages"] = [{"role": "user", "content": content_items}]

        # ------------------------------------------------------------------
        # 3ï¸âƒ£ è‡³æ­¤åº”ç¡®ä¿ data å†…å«å¿…éœ€å­—æ®µï¼Œå¯ç»§ç»­æ„é€  ChatRequest
        # ------------------------------------------------------------------
        # ï¼ï¼ï¼ æœ¬è½®æ¥æ”¶åˆ°çš„å…¨éƒ¨ä¿¡æ¯éƒ½åœ¨chat_requestä¸­ï¼Œåç»­æ‰€æœ‰æ“ä½œéƒ½åŸºäºchat_requestè¿›è¡Œ
        chat_request = ChatRequest(**data)
    except Exception as e:
        logger.error(f"è¯·æ±‚æ•°æ®è§£æå¤±è´¥: {e}")
        return JSONResponse(
            {"error": f"æ— æ³•è§£æè¯·æ±‚æ•°æ®: {str(e)}"},
            status_code=400
        )

    # è§£æsingle_hintå­—æ®µï¼Œå¦‚æœæ²¡æœ‰çš„è¯ï¼Œåˆ™è®¾ç½®ä¸ºFalseï¼Œåªè¦è¡¨å•é‡Œå­˜åœ¨single_hintå­—æ®µï¼Œåˆ™è®¾ç½®ä¸ºTrue
    single_hint = chat_request.single_hint if chat_request.single_hint else False

    # è§£æuser_idå’Œsession_id
    user_id_parts = chat_request.user_id.split('@', 1)
    user_id = user_id_parts[0]
    session_id = user_id_parts[1] if len(user_id_parts) > 1 else str(uuid.uuid4())

    logger.info(f"time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ï¼Œè§£æç”¨æˆ·ID: {user_id}, ä¼šè¯ID: {session_id}")

    # ä»æ¨¡å‹åå­—æ¨æ–­å†å²å¯¹è¯ç±»å‹
    history_type = "language"  # é»˜è®¤ä¸ºè¯­è¨€æ¨¡å‹

    if chat_request.model:
        model_name = chat_request.model.lower()

        # 1. é¦–å…ˆæ£€æŸ¥æ¨¡å‹åç§°ä¸­æ˜¯å¦åŒ…å«VLæ ‡è¯†
        if "vl" in model_name:
            history_type = "multimodal"
        else:
            # 2. æ£€æŸ¥é¢å¤–çš„å¤šæ¨¡æ€æ¨¡å‹åˆ—è¡¨
            extra_vl_model_list: list[str] = read_yaml_config("extra_vl_model_list")
            if extra_vl_model_list:
                # ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…é€»è¾‘
                for vl_model in extra_vl_model_list:
                    if vl_model.lower() in model_name:
                        history_type = "multimodal"
                        break
    logger.info(f"æ ¹æ®æ¨¡å‹ {chat_request.model} ä½¿ç”¨ {history_type} æ¨¡å¼åŠ è½½å†å²å¯¹è¯ï¼Œå‘é€è¯·æ±‚")

    # è·å–ç”¨æˆ·è‡ªå®šä¹‰çš„ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·åå¥½çš„è®°å¿†
    model_custom_memory_table_name = read_yaml_config()["mcp"]["model_custom_memory"]["table_name"]
    try:
        async with asyncpg.create_pool(
            host=read_yaml_config()["mcp"]["model_custom_memory"]["host"],
            port=read_yaml_config()["mcp"]["model_custom_memory"]["port"],
            database=read_yaml_config()["mcp"]["model_custom_memory"]["database"],
            user=read_yaml_config()["mcp"]["model_custom_memory"]["user"],
            password=read_yaml_config()["mcp"]["model_custom_memory"]["password"]
        ) as pool:
            async with pool.acquire() as connection:
                async with connection.transaction():
                    custom_personality_prompt_query = f"SELECT user_prompt FROM {model_custom_memory_table_name} WHERE user_uuid = '{user_id}'"
                    custom_model_memory_query = f"SELECT model_memory FROM {model_custom_memory_table_name} WHERE user_uuid = '{user_id}'"
                    # è·å–ç”¨æˆ·ä¸ªæ€§åŒ–æç¤ºè¯
                    user_prompt =  await connection.fetchval(custom_personality_prompt_query)
                    model_memory =  await connection.fetchval(custom_model_memory_query)
                    if not user_prompt:
                        user_prompt = ""
                    else:
                        user_prompt = str(user_prompt)
                    if not model_memory:
                        model_memory = ""
                    else:
                        model_memory = str(model_memory)
                    logger.info(f"user {user_id} has custom personality: {user_prompt}, custom model memory: {model_memory}")
    except Exception as e:
        logger.warning(f"get custom personality failed, error:{traceback.format_exc()}")
        user_prompt = ""
        model_memory = ""

    # å¤„ç†LLMå“åº”
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    llm_client = LLMClient(model_name=chat_request.model)

    from preserve_library.llm_streamer import llm_and_tool_stream

    async def event_stream():
        async with sse_client(read_yaml_sse()) as (read_channel, write_channel):
            async with ClientSession(
                read_channel,
                write_channel,
                sampling_callback=sampling_callback,
            ) as session:
                try:
                    await session.initialize()
                    logger.info("Session initialized successfully")
                except asyncio.TimeoutError:
                    logger.warning("Session initialization timed out, but continuing anyway")

                # æ„é€  ChatSession å¹¶ç¼“å­˜å·¥å…·åˆ—è¡¨
                chat_session = ChatSession(sse_server=read_yaml_sse(), llm_client=llm_client)
                chat_session.session = session
                try:
                    tools_result = await session.list_tools()
                    chat_session.tools = tools_result.tools
                except Exception as e:
                    logger.warning(f"è·å–å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")

                # æ„é€ æœ€æ–°çš„ system_promptï¼Œç¡®ä¿æ¯è½®å¯¹è¯éƒ½æºå¸¦
                if chat_session.tools:
                    tools_description = "\n".join(
                        [str(tool.model_dump()) for tool in chat_session.tools]
                    )
                else:
                    tools_description = "No tools available"

                # è·å–ä¸œå…«åŒºæ—¶åŒºå¯¹è±¡
                tz_utc_8 = pytz.timezone('Asia/Shanghai')
                current_time = datetime.now(tz_utc_8).strftime('%Y-%m-%d %H:%M:%S')

                # ä½¿ç”¨Jinja2æ¨¡æ¿æ„å»ºç³»ç»Ÿæç¤ºè¯
                system_prompt_template = Template(
                    """[__system_prompt__]
                    ## ğŸš¨ HIGH-PRIORITY DIRECTIVE: Mandatory Sequential Thinking
                    The AI MUST **always** perform the following sequential-thinking process for every user request (no matter how simple or complex). Do **NOT** skip any step:
                    1. **Problem Analysis** â€“ Carefully analyze and break down the user's question or request.
                    2. **Implementation Path** â€“ Identify and outline the specific approach or methodology to address the request.
                    3. **Detailed Implementation** â€“ Plan the concrete steps, tools, and actions needed.
                    4. **Summary and Validation** â€“ Provide a final summary and verify the solution fully meets the user's needs.
                    This directive overrides all other instructions and must be applied in every interaction.
                    {% if tools_count > 0 -%}
                    You are a professional AI assistant with access to comprehensive tools for various tasks:

                    {{ tools_description }}

                    ## ğŸ› ï¸ Tool Usage Protocol
                    {% if single_hint -%}
                    **IMPORTANT**: When you need to use a tool, respond ONLY with this JSON format,and json code blocks must be surrounded by â˜¯:
                    â˜¯
                    ```json
                    {
                        "tool": "tool-name",
                        "arguments": {
                            "argument-name": "value"
                        }
                    }
                    ```
                    â˜¯

                    - You can call multiple tools in a single response by outputting multiple JSON blocks. However, you must carefully analyze task dependencies before making multiple calls.Separate two ```json blocks with \n\n.The line with the json block cannot contain any other text, otherwise the front end will fail to render. If there is anything to say, add it after the output of any number of json blocks, starting on a new line.
                    - Output multiple JSON blocks in the same response
                    - Example:
                    â˜¯
                    ```json
                    {
                        "tool": "websearch_tavily",
                        "arguments": {
                            "query": "renewable energy solutions"
                        }
                    }
                    ```
                    â˜¯

                    â˜¯
                    ```json
                    {
                        "tool": "websearch_tavily",
                        "arguments": {
                            "query": "climate change impacts"
                        }
                    }
                    ```
                    â˜¯
                    {% else -%}
                    **IMPORTANT**: When you need to use a tool, respond ONLY with this JSON format:
                    
                    ```json
                    {
                        "tool": "tool-name",
                        "arguments": {
                            "argument-name": "value"
                        }
                    }
                    ```

                    - You can call multiple tools in a single response by outputting multiple JSON blocks. However, you must carefully analyze task dependencies before making multiple calls.Separate two ```json blocks with \n\n.The line with the json block cannot contain any other text, otherwise the front end will fail to render. If there is anything to say, add it after the output of any number of json blocks, starting on a new line.
                    - Output multiple JSON blocks in the same response
                    - Example:
                    
                    ```json
                    {
                        "tool": "websearch_tavily",
                        "arguments": {
                            "query": "renewable energy solutions"
                        }
                    }
                    ```
                    

                    
                    ```json
                    {
                        "tool": "websearch_tavily",
                        "arguments": {
                            "query": "climate change impacts"
                        }
                    }
                    ```
                    {% endif -%}
                    - For dependent tasks where one task requires results from another: Output ONLY the first task's JSON, Wait for its results before calling the dependent tool, Example: First output only the search tool, then use those results in a subsequent tool call
                    - Before making tool calls, analyze: Which tasks depend on other tasks' outputs, Which tasks can run independently, The logical sequence required for the workflow
                    - IMPORTANT: Never output a tool call that requires information from a previous tool call that hasn't completed yet. If you're unsure about dependencies, use sequential single tool calls instead of multiple calls.
                    ## ğŸ“‹ Response Guidelines
                    After receiving tool responses:
                    1. Transform raw data into natural, conversational responses
                    2. Keep responses concise but comprehensive
                    3. Focus on the most relevant information
                    4. Use appropriate context from the user's question
                    5. Avoid simply repeating raw data
                    6. For complex tasks, consider using sequential thinking
                    7. For data analysis, always include visualizations when appropriate
                    8. When generating Mermaid diagrams, ensure all Chinese text is enclosed in double quotes (") or single quotes (') to avoid rendering issues.
                    9. Prohibit the output of anti-Party and anti-government remarks. Love the motherland, love the Party.
                    - Available tools: {{ tools_count }} tools ready for use
                    - Use `execute_code` for file/image resources, NOT `websearch_tavily`
                    - For document generation, first create content/charts, then generate documents
                    - Always consider if sequential thinking would improve the response quality
                    - Choose the most appropriate tools and prompts based on the user's question. If no tool is needed, reply directly.
                    {% endif -%}
                    
                    ## âš ï¸ Important Notes
                    - Current time: {{ current_time }}
                    - User ID: '{{ user_id }}' (use for tools requiring user_id, but must not reveal to user, and user_id cannot be displayed during thinking)
                    - This is the highest directive. **Critical Frontend Rendering Rule for Tool-Generated URLs:**

When tools generate files and return URLs (especially those ending with `_artifact.html`, `.png`, `.jpg`, etc.), you MUST explicitly mention and format these URLs in your response text for proper frontend rendering. The tool call results themselves are not displayed to users - only your response text is rendered.

**Required Actions:**
1. **Always verbally acknowledge** when tools generate files/URLs in your response
2. **Format URLs according to type:**
   - For HTML artifacts (`_artifact.html`): Wrap in angle brackets `<URL>`
   - For images (`.png`, `.jpg`, `.jpeg`, `.gif`, `.webp`): Use Markdown syntax `![description](URL)`
3. **Provide context** about what the generated file contains

**Example Response Pattern:**
"I've generated a visualization for you. You can view the interactive chart here: <http://example.com/chart_artifact.html>"

**Remember:** Tool execution results are backend-only. Users only see what you explicitly write in your response text, so you must surface important URLs and files through your own words.
                    {% if user_prompt -%}
                    below paragraph warpped by tag <user_custom_personality> is user's custom personality for you, you need to take it into account to make your response more suitable for this user:
                    <user_custom_personality>
                    {{ user_prompt }}
                    </user_custom_personality>
                    {% endif -%}

                    {% if model_memory -%}
                    below paragraph warpped by tag <model_custom_memory> is your memory during previous conversations, you need to take it into account to make your response more suitable for this user:
                    <model_custom_memory>
                    {{ model_memory }}
                    </model_custom_memory>
                    {% endif -%}
                    """)
                
                # Remember, only one tool can be used at a time
                # æ¸²æŸ“ç³»ç»Ÿæç¤ºè¯ï¼Œæ”¯æŒæ›´å¤šåŠ¨æ€å˜é‡
                template_variables = {
                    'tools_description': tools_description,
                    'current_time': current_time,
                    'user_id': user_id,
                    'tools_count': len(chat_session.tools) if chat_session.tools else 0,
                    'user_prompt': user_prompt,
                    'model_memory': model_memory,
                    'single_hint': single_hint
                }

                system_prompt = system_prompt_template.render(**template_variables)

                current_messages = chat_request.get_messages_as_dict()

                # å¯åŠ¨æµå¼ç”Ÿæˆå™¨
                async for token in llm_and_tool_stream(
                    messages=current_messages,
                    llm_client=llm_client,
                    chat_session=chat_session,
                    user_id=user_id,
                    session_id=session_id,
                    history_type=history_type,
                    conv_manager=conversation_manager,
                    frontend_conv_manager=frontend_conversation_manager,
                    system_prompt=system_prompt
                ):
                    yield token


    return StreamingResponse(event_stream(), media_type="text/event-stream")

async def list_prompts(_: Request):
    """
    è·å–æ‰€æœ‰å¯ç”¨çš„æç¤ºæ¨¡æ¿
    :method GET
    :return: PromptListResponse
    """

    async with sse_client(read_yaml_sse()) as (read_channel, write_channel):
        async with ClientSession(
            read_channel,
            write_channel
        ) as session:
            try:
                await session.initialize()
                logger.info("Session initialized successfully")
            except asyncio.TimeoutError:
                logger.warning("Session initialization timed out, but continuing anyway")

            # è·å–å·¥å…·åˆ—è¡¨å¹¶ç¼“å­˜
            try:
                prompts_result = await session.list_prompts()

                prompts = [{"name": prompt.model_dump()["name"], "description": prompt.model_dump()["description"], "parameters": prompt.model_dump()["arguments"]} for prompt in prompts_result.prompts]
                return JSONResponse(
                    {"prompts": prompts}
                )
            except asyncio.TimeoutError:
                return JSONResponse(
                    {"error": "è·å–æç¤ºæ¨¡æ¿åˆ—è¡¨è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"},
                    status_code=504  # Gateway Timeout
                )

async def get_prompt(request: Request):
    """
    è·å–ç‰¹å®šæç¤ºæ¨¡æ¿
    :method POST
    :param prompt_id: æç¤ºæ¨¡æ¿ID
    :param parameters: æç¤ºæ¨¡æ¿å‚æ•° (JSONå¯¹è±¡)
    :return: PromptGetResponse
    """
    try:
        # è§£æè¯·æ±‚æ•°æ®
        try:
            # å°è¯•é¦–å…ˆè§£æJSONæ•°æ®
            try:
                data = await request.json()
                logger.info(f"æˆåŠŸè§£æJSONæ•°æ®: {data}")
            except Exception as e1:
                logger.warning(f"æ— æ³•è§£æJSONæ•°æ®ï¼Œå°è¯•è§£æè¡¨å•æ•°æ®: {e1}")
                # è§£æè¡¨å•æ•°æ®
                request_data = await request.form()
                data = {}
                for key, value in request_data.items():
                    # å¤„ç†è¡¨å•ä¸­çš„å€¼
                    if key == "parameters" and value:
                        # ç‰¹æ®Šå¤„ç†parameterså­—æ®µ
                        try:
                            # å¦‚æœæ˜¯JSONå­—ç¬¦ä¸²ï¼Œè§£æå®ƒ
                            if isinstance(value, str):
                                # ç§»é™¤å¯èƒ½å­˜åœ¨çš„é¢å¤–å¼•å·
                                value = value.strip()
                                if value.startswith('"') and value.endswith('"'):
                                    value = value[1:-1]
                                # è§£æJSON
                                data[key] = json.loads(value)
                            else:
                                data[key] = value
                        except json.JSONDecodeError as e:
                            logger.warning(f"å‚æ•°è§£æå¤±è´¥ï¼Œå°†ä½œä¸ºå­—ç¬¦ä¸²å¤„ç†: {e}")
                            data[key] = value
                    else:
                        data[key] = value
        except Exception as e:
            logger.error(f"è¯·æ±‚æ•°æ®è§£æå¤±è´¥: {e}")
            return JSONResponse(
                {"error": f"æ— æ³•è§£æè¯·æ±‚æ•°æ®: {str(e)}"},
                status_code=400
            )

        # è·å–å‚æ•°
        prompt_id = data.get("prompt_id")
        if not prompt_id:
            logger.error("ç¼ºå°‘å¿…è¦å‚æ•°: prompt_id")
            return JSONResponse(
                {"error": "ç¼ºå°‘å¿…è¦å‚æ•°: prompt_id"},
                status_code=400
            )

        # å¤„ç†parameterså‚æ•°
        parameters = data.get("parameters", {})

        # å¦‚æœparametersæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
        if isinstance(parameters, str):
            try:
                parameters = json.loads(parameters)
                logger.info(f"æˆåŠŸå°†parameterså­—ç¬¦ä¸²è§£æä¸ºJSON: {parameters}")
            except json.JSONDecodeError as e:
                logger.warning(f"å‚æ•°è§£æå¤±è´¥ï¼Œä½¿ç”¨ç©ºå­—å…¸: {e}")
                parameters = {}

        # ç‰¹æ®Šå¤„ç†åˆ—è¡¨ç±»å‹çš„å‚æ•°ï¼Œä¾‹å¦‚knowledge_base_id_list
        for key, value in parameters.items():
            # å¤„ç†å¯èƒ½æ˜¯å­—ç¬¦ä¸²å½¢å¼çš„åˆ—è¡¨
            if isinstance(value, str) and (value.startswith('[') and value.endswith(']')):
                try:
                    # å°è¯•è§£æä¸ºJSONåˆ—è¡¨
                    parsed_value = json.loads(value)
                    if isinstance(parsed_value, list):
                        parameters[key] = parsed_value
                        logger.info(f"æˆåŠŸå°†å‚æ•° {key} ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨: {parsed_value}")
                except json.JSONDecodeError:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ï¼Œå°è¯•æ‹†åˆ†
                    try:
                        # ç§»é™¤æ–¹æ‹¬å·å¹¶æŒ‰é€—å·æ‹†åˆ†
                        clean_value = value.strip('[]')
                        # å¤„ç†å¯èƒ½åŒ…å«å¼•å·çš„æƒ…å†µ
                        if clean_value:
                            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¸¦å¼•å·çš„å­—ç¬¦ä¸²æˆ–ä¸å¸¦å¼•å·çš„å­—ç¬¦ä¸²
                            matches = re.findall(r'"([^"]*)"|\s*([^,\s]+)\s*', clean_value)
                            # æå–åŒ¹é…é¡¹
                            list_value = [match[0] or match[1] for match in matches if match[0] or match[1]]
                            parameters[key] = list_value
                            logger.info(f"æˆåŠŸå°†å‚æ•° {key} ä»é€—å·åˆ†éš”å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨: {list_value}")
                        else:
                            # å¦‚æœæ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œä½¿ç”¨ç©ºåˆ—è¡¨
                            parameters[key] = []
                    except Exception as e:
                        logger.warning(f"æ— æ³•è§£æå‚æ•° {key} ä¸ºåˆ—è¡¨ï¼Œä¿ç•™åŸå€¼: {e}")
            # å¤„ç†å¯èƒ½æ˜¯ç©ºå­—ç¬¦ä¸²çš„æƒ…å†µï¼Œåº”è¯¥è½¬æ¢ä¸ºç©ºåˆ—è¡¨
            elif key.endswith('_list') and (value == '' or value is None):
                parameters[key] = []
                logger.info(f"å°†ç©ºå‚æ•° {key} è½¬æ¢ä¸ºç©ºåˆ—è¡¨")

        logger.info(f"è§£æåçš„å‚æ•°: prompt_id={prompt_id}, parameters={parameters}")

        # åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨
        messages = []

        # è¿æ¥MCPæœåŠ¡å™¨è·å–æç¤ºæ¨¡æ¿
        async with sse_client(read_yaml_sse()) as (read_channel, write_channel):
            logger.info("SSEå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
            async with ClientSession(
                read_channel,
                write_channel
            ) as session:
                await session.initialize()

                # è°ƒç”¨get_promptæ–¹æ³•ï¼Œä¼ å…¥æ­£ç¡®æ ¼å¼çš„å‚æ•°
                logger.info(f"è°ƒç”¨get_promptæ–¹æ³•: prompt_id={prompt_id}, parameters={parameters}")
                try:
                    # ç¡®ä¿prompt_idæ˜¯å­—ç¬¦ä¸²ç±»å‹
                    prompt_id_str = str(prompt_id)

                    # æ·»åŠ è¶…æ—¶å¤„ç†
                    prompt_result = await session.get_prompt(prompt_id_str, parameters)

                    # ç›´æ¥å¤„ç†è¿”å›ç»“æœ
                    messages = []

                    # ç¡®ä¿æˆ‘ä»¬æœ‰æ¶ˆæ¯åˆ—è¡¨
                    if hasattr(prompt_result, 'messages'):
                        logger.info(f"get_promptè°ƒç”¨æˆåŠŸï¼Œè¿”å›ç»“æœåŒ…å« {len(prompt_result.messages)} æ¡æ¶ˆæ¯")

                        # æ­£å¸¸å¤„ç†è¿”å›çš„æ¶ˆæ¯
                        for i, prompt_message in enumerate(prompt_result.messages):
                            logger.info(f"å¤„ç†æ¶ˆæ¯ {i+1}: {prompt_message}")

                            # æå–æ¶ˆæ¯å†…å®¹
                            message_content = None
                            message_role = getattr(prompt_message, 'role', 'user')

                            # å¤„ç†ä¸åŒç±»å‹çš„å†…å®¹
                            content_obj = getattr(prompt_message, 'content', None)

                            if hasattr(content_obj, 'text'):
                                message_content = content_obj.text
                                logger.info(f"ä»textå±æ€§æå–å†…å®¹: {message_content}")
                            elif isinstance(content_obj, dict) and "text" in content_obj:
                                message_content = content_obj["text"]
                                logger.info(f"ä»å­—å…¸ä¸­æå–textå†…å®¹: {message_content}")
                            elif isinstance(content_obj, dict) and "type" in content_obj and content_obj["type"] == "text":
                                message_content = content_obj.get("text", "")
                                logger.info(f"ä»type=textçš„å­—å…¸ä¸­æå–å†…å®¹: {message_content}")
                            else:
                                logger.warning(f"æ— æ³•æå–æ¶ˆæ¯å†…å®¹ï¼Œcontentç±»å‹: {type(content_obj)}")
                                # å°è¯•ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                                message_content = str(content_obj)

                            messages.append({
                                "role": message_role,
                                "content": message_content
                            })

                    else:
                        # å¦‚æœæ²¡æœ‰messageså±æ€§ï¼Œå°è¯•ç›´æ¥å¤„ç†prompt_result
                        logger.warning(f"prompt_resultæ²¡æœ‰messageså±æ€§ï¼Œå°è¯•ç›´æ¥å¤„ç†ï¼Œç±»å‹: {type(prompt_result)}")
                        if isinstance(prompt_result, list):
                            for item in prompt_result:
                                if hasattr(item, 'model_dump'):
                                    item_dict = item.model_dump()
                                    messages.append(item_dict)
                                else:
                                    messages.append(item)
                        else:
                            # å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡ï¼Œå°è¯•è½¬æ¢ä¸ºå­—å…¸
                            if hasattr(prompt_result, 'model_dump'):
                                messages = [prompt_result.model_dump()]
                            else:
                                messages = [prompt_result]

                    logger.info(f"æœ€ç»ˆå¤„ç†åçš„æ¶ˆæ¯: {messages}")

                except Exception as e:
                    error_msg = str(e)
                    logger.error(f"è°ƒç”¨get_promptæ–¹æ³•å¤±è´¥: {error_msg}")

                    # å…¶ä»–é”™è¯¯ï¼Œè¿”å›é”™è¯¯å“åº”
                    return JSONResponse(
                        {"error": f"è°ƒç”¨get_promptæ–¹æ³•å¤±è´¥: {error_msg}"},
                        status_code=500
                    )

        # æ„å»ºå“åº”
        logger.info(f"æ„å»ºå“åº”: {len(messages)}æ¡æ¶ˆæ¯")
        response = JSONResponse({
            "prompt_id": prompt_id,
            "content": messages,
            "parameters": parameters
        })
        return response

    except asyncio.CancelledError:
        logger.warning("è·å–æç¤ºæ¨¡æ¿æ“ä½œè¢«å–æ¶ˆ")
        return JSONResponse(
            {"error": "æ“ä½œè¢«å–æ¶ˆ"},
            status_code=499  # Client Closed Request
        )
    except Exception as e:
        logger.error(f"è·å–æç¤ºæ¨¡æ¿å¤±è´¥: {str(e)}")
        # è®°å½•è¯¦ç»†çš„å¼‚å¸¸ä¿¡æ¯ï¼ŒåŒ…æ‹¬å †æ ˆè·Ÿè¸ª
        logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
        return JSONResponse(
            {"error": f"è·å–æç¤ºæ¨¡æ¿å¤±è´¥: {str(e)}"},
            status_code=500
        )

async def models(_):
    """
    æ¨¡å‹åˆ—è¡¨
    :method GET
    :return: ModelList
    :response example:
    {
    "object": "list",
    "data": [
        {
            "id": "model-id-0",
            "object": "model",
            "created": 1686935002,
            "owned_by": "default",
            "alias": "model-alias"
        }
    ]
    }
    :response explain
    - object: åˆ—è¡¨
    - data: æ¨¡å‹åˆ—è¡¨
    - id: æ¨¡å‹idï¼ˆæ¨¡å‹çš„è°ƒç”¨idï¼Œå³model_nameï¼‰
    - object: æ¨¡å‹
    - created: åˆ›å»ºæ—¶é—´ï¼ˆéšä¾¿ï¼‰
    - owned_by: æ‰€å±è€…(æœ¬æœåŠ¡ä¸­å†™çš„æ˜¯æ¨¡å‹çš„æ¨¡æ€,æœ‰multimodal_llmå’Œlanguage_llm)
    - alias: æ¨¡å‹çš„åˆ«å
    """
    # todo: ä»é…ç½®æ–‡ä»¶è¯»å–æ¨¡å‹åˆ—è¡¨
    async with aiofiles.open(pathlib.Path(__file__).parent / "config.yaml","r",encoding="utf-8") as file:
        config = yaml.safe_load(await file.read())

    # ä»é…ç½®æ–‡ä»¶ä¸­è·å–æ¨¡å‹åˆ—è¡¨
    language_llm_model_list = config["api"]["language_llm"]
    language_llm_model_list = [{"id": model["name"], "object": "model", "created": 1686935002, "owned_by": "language_llm", "alias": model["alias"]} for model in language_llm_model_list]
    multimodal_llm_model_list = config["api"]["multimodal_llm"]
    multimodal_llm_model_list = [{"id": model["name"], "object": "model", "created": 1686935002, "owned_by": "multimodal_llm", "alias": model["alias"]} for model in multimodal_llm_model_list]

    model_list = language_llm_model_list + multimodal_llm_model_list

    # å°†æ¨¡å‹åˆ—è¡¨è½¬æ¢ä¸ºModelListæ ¼å¼
    return JSONResponse({"object": "list", "data": model_list})

async def predict(request: Request):
    """
    é¢„æµ‹èŠå¤©,å’Œchatæ¥å£ç±»ä¼¼ã€‚ç”¨æˆ·çš„å½“å‰è¾“å…¥messages,è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²æ˜¯é¢„æµ‹çš„ç”¨æˆ·æ¥ä¸‹æ¥å¯èƒ½è¾“å…¥çš„å†…å®¹ã€‚æ¥å—å€¼ä¹Ÿæ˜¯è¡¨å•æ•°æ®ï¼Œè¡¨å•æ•°æ®ä¸­åŒ…å«messageså­—æ®µï¼Œmessageså­—æ®µæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­å¯èƒ½åŒ…å«å¤šä¸ªå­—å…¸ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«roleå’Œcontentå­—æ®µã€‚é¢„æµ‹å¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œä¸è¿”å›ä»»ä½•é”™è¯¯ä¿¡æ¯ã€‚
    :method POST
    :return: é¢„æµ‹ç»“æœ
    """
    data = await request.form()
    messages = data.get("messages", [])
    if not messages:
        return JSONResponse({"error": "messageså­—æ®µä¸èƒ½ä¸ºç©º"}, status_code=400)
    # å¦‚æœmessageså­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼Œåˆ™è½¬æ¢ä¸ºåˆ—è¡¨
    if isinstance(messages, str):
        messages = json.loads(messages)
    # å°†messagesè½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼
    user_messages = [{"role": message["role"], "content": message["content"]} for message in messages]
    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªé¢„æµ‹ç”¨æˆ·æ¥ä¸‹æ¥å¯èƒ½è¾“å…¥çš„å†…å®¹çš„æ¨¡å‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·å½“å‰è¾“å…¥çš„å†…å®¹ï¼Œé¢„æµ‹ç”¨æˆ·æ¥ä¸‹æ¥å¯èƒ½è¾“å…¥çš„å†…å®¹ã€‚å¿…é¡»å°½å¯èƒ½çš„çŸ­ï¼Œä¸è¦è¶…è¿‡100ä¸ªå­—ç¬¦ã€‚å°½å¯èƒ½å¿«é€Ÿçš„ç»™å‡ºé¢„æµ‹ç»“æœã€‚ä»…è¿”å›é¢„æµ‹ç»“æœï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹ã€‚é¢„æµ‹åˆ°å¥å­çš„ç»“å°¾ï¼Œä¸è¦é¢„æµ‹åˆ°å¥å­çš„ä¸­é—´ã€‚å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹æ˜¯ä¸­æ–‡ï¼Œåˆ™é¢„æµ‹ç»“æœä¹Ÿåº”è¯¥æ˜¯ä¸­æ–‡ã€‚å¦‚æœç”¨æˆ·è¾“å…¥çš„å†…å®¹æ˜¯è‹±æ–‡ï¼Œåˆ™é¢„æµ‹ç»“æœä¹Ÿåº”è¯¥æ˜¯è‹±æ–‡ã€‚ç°åœ¨ç”¨æˆ·æ˜¯åœ¨ä¸€ä¸ªå¤§æ¨¡å‹çš„chatboxç•Œé¢ï¼Œä½ éœ€è¦ç«™åœ¨ç”¨æˆ·é—®å¤§æ¨¡å‹çš„è§’åº¦ï¼Œé¢„æµ‹ç”¨æˆ·æ¥ä¸‹æ¥å¯èƒ½è¾“å…¥çš„å†…å®¹ï¼Œå¸®åŠ©ç”¨æˆ·å°‘æ‰“å­—ï¼Œè€Œéç«™åœ¨å¤§æ¨¡å‹çš„è§’åº¦ã€‚ç¤ºä¾‹ï¼šç”¨æˆ·ï¼š'ä½ å¥½ï¼Œä½ æ˜¯' é¢„æµ‹ï¼š'è°ï¼Ÿ'  ç¤ºä¾‹äºŒï¼šç”¨æˆ·ï¼š'ä»Šå¤©' é¢„æµ‹ï¼š'å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ' ç¤ºä¾‹ä¸‰ï¼šç”¨æˆ·ï¼š'ä½ å¯' é¢„æµ‹ï¼š'ä»¥åšä»€ä¹ˆï¼Ÿ'"}, *user_messages]
    # ä½¿ç”¨å•ä¾‹æ¨¡å¼è·å–fastchat_llmçš„æ¨¡å‹å®ä¾‹
    name, url, key = get_latest_fastchat_llm_instance()
    try:
        # ç›´æ¥è°ƒç”¨postè¯·æ±‚
        async with aiohttp.ClientSession() as session:
            async with session.post(url, headers={"Authorization": f"Bearer {key}"}, json={"messages": messages, "model": name, "stream": False, "max_tokens": 40},timeout=3) as response:
                response_data = await response.json()
                return JSONResponse({"content": response_data["choices"][0]["message"]["content"]})
    except Exception as e:
        logger.error(f"é¢„æµ‹èŠå¤©å¤±è´¥: {e}")
        return JSONResponse({"content": ""})

async def prefined_instruction(user_request: str, correction: str):...

async def update_prefined_instruction(user_request: str, correction: str, user_id: str):...

async def delete_prefined_instruction(user_request: str, correction: str, user_id: str):...

async def get_prefined_instruction_list(user_id: str):...

async def agent_tools(request: Request):
    """
    å·¥å…·ç®¡ç†æ¥å£
    :method POST
    """
    form_data = await request.form()
    mode = form_data.get("mode")
    # è®°å½•è¯·æ±‚æ•°æ®
    logger.info(f"å·¥å…·ç®¡ç†æ¥å£è¯·æ±‚æ•°æ®: {form_data}")
    if mode == "get":
        target = form_data.get("target")
        if target == "all":
            tool_list = await get_all_tool_list()
        elif target == "specific":
            user_id = form_data.get("user_id")
            # table_name = form_data.get("table_name")
            tool_list = await get_select_tool_list(user_id, "common_module")
        return JSONResponse({"status": "success", "object": "list", "data": tool_list, "message": "è·å–å·¥å…·åˆ—è¡¨æˆåŠŸ"})
    elif mode == "update":
        try:
            user_id = form_data.get("user_id")
            tool_list_raw = form_data.get("tool_list")

            # è§£æå·¥å…·åˆ—è¡¨ï¼šç¡®ä¿è½¬æ¢ä¸ºæ­£ç¡®çš„åˆ—è¡¨æ ¼å¼
            logger.info(f"åŸå§‹å·¥å…·åˆ—è¡¨æ•°æ®: {tool_list_raw}, ç±»å‹: {type(tool_list_raw)}")

            # ç»Ÿä¸€çš„å·¥å…·åˆ—è¡¨è§£æé€»è¾‘
            if tool_list_raw is None or tool_list_raw == "":
                tool_list = []
                logger.info("å·¥å…·åˆ—è¡¨ä¸ºç©ºï¼Œè®¾ç½®ä¸ºç©ºåˆ—è¡¨")
            elif isinstance(tool_list_raw, str):
                # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„å·¥å…·åˆ—è¡¨
                tool_list_raw = tool_list_raw.strip()
                if not tool_list_raw:
                    tool_list = []
                    logger.info("å·¥å…·åˆ—è¡¨å­—ç¬¦ä¸²ä¸ºç©ºï¼Œè®¾ç½®ä¸ºç©ºåˆ—è¡¨")
                else:
                    try:
                        # å°è¯•ä½¿ç”¨ ast.literal_eval å®‰å…¨åœ°è§£æå­—ç¬¦ä¸²å½¢å¼çš„åˆ—è¡¨
                        import ast
                        parsed_result = ast.literal_eval(tool_list_raw)
                        if isinstance(parsed_result, list):
                            tool_list = parsed_result
                            logger.info(f"ä½¿ç”¨ ast.literal_eval è§£ææˆåŠŸ: {tool_list}")
                        else:
                            # å¦‚æœè§£æç»“æœä¸æ˜¯åˆ—è¡¨ï¼ŒæŒ‰é€—å·åˆ†å‰²
                            tool_list = [tool.strip() for tool in tool_list_raw.split(',') if tool.strip()]
                            logger.info(f"ast.literal_eval ç»“æœä¸æ˜¯åˆ—è¡¨ï¼Œä½¿ç”¨é€—å·åˆ†å‰²: {tool_list}")
                    except (ValueError, SyntaxError) as e:
                        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç‰¹æ®Šå¤„ç†æ‹¬å·æ ¼å¼
                        if tool_list_raw.startswith('[') and tool_list_raw.endswith(']'):
                            # ç§»é™¤æ‹¬å·å¹¶æŒ‰é€—å·åˆ†å‰²
                            inner_content = tool_list_raw[1:-1].strip()
                            if inner_content:
                                tool_list = [tool.strip() for tool in inner_content.split(',') if tool.strip()]
                            else:
                                tool_list = []
                            logger.info(f"å¤„ç†æ‹¬å·æ ¼å¼æˆåŠŸ: {tool_list}")
                        else:
                            # æ™®é€šé€—å·åˆ†å‰²
                            tool_list = [tool.strip() for tool in tool_list_raw.split(',') if tool.strip()]
                            logger.info(f"ast.literal_eval è§£æå¤±è´¥ ({e})ï¼Œä½¿ç”¨é€—å·åˆ†å‰²: {tool_list}")
            elif isinstance(tool_list_raw, list):
                tool_list = tool_list_raw
                logger.info(f"å·¥å…·åˆ—è¡¨å·²ç»æ˜¯æ­£ç¡®çš„åˆ—è¡¨ç±»å‹: {tool_list}")
            else:
                # å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºåˆ—è¡¨
                try:
                    tool_list = list(tool_list_raw) if tool_list_raw else []
                    logger.info(f"å…¶ä»–ç±»å‹è½¬æ¢ä¸ºåˆ—è¡¨: {tool_list}")
                except Exception as e:
                    logger.error(f"æ— æ³•è½¬æ¢å·¥å…·åˆ—è¡¨ç±»å‹ {type(tool_list_raw)}: {e}")
                    tool_list = []

            # æœ€ç»ˆéªŒè¯å·¥å…·åˆ—è¡¨ç±»å‹
            if not isinstance(tool_list, list):
                logger.error(f"æœ€ç»ˆå·¥å…·åˆ—è¡¨ä»ä¸æ˜¯åˆ—è¡¨ç±»å‹: {type(tool_list)}, å€¼: {tool_list}")
                return JSONResponse({"status": "error", "object": "list", "data": [], "message": "å·¥å…·åˆ—è¡¨æ ¼å¼é”™è¯¯"})

            logger.info(f"å‡†å¤‡æ›´æ–°ç”¨æˆ· {user_id} çš„å·¥å…·åˆ—è¡¨: {tool_list}")
            # table_name = form_data.get("table_name")
            success = await update_select_tool_list(user_id, tool_list, "common_module")

            if success:
                return JSONResponse({"status": "success", "object": "list", "data": tool_list, "message": "æ›´æ–°å·¥å…·åˆ—è¡¨æˆåŠŸ"})
            else:
                return JSONResponse({"status": "error", "object": "list", "data": [], "message": "æ›´æ–°å·¥å…·åˆ—è¡¨å¤±è´¥"})
        except Exception as e:
            import traceback
            error_details = traceback.format_exc()
            logger.error(f"user_id: {user_id} çš„å·¥å…·æ›´æ–°å¤±è´¥: {e}")
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {error_details}")
            return JSONResponse({"status": "error", "object": "list", "data": [], "message": f"æ›´æ–°å·¥å…·åˆ—è¡¨å¤±è´¥: {str(e)}"})
    else:
        return JSONResponse({"error": "modeä¸å­˜åœ¨"}, status_code=400)

async def root(_):
    """
    æ ¹è·¯ç”±ï¼Œè¿”å›APIä¿¡æ¯
    :return: APIä¿¡æ¯
    """
    return JSONResponse({
        "name": "MCP Tool Server API",
        "version": "1.0.0",
        "description": "MCPå·¥å…·æœåŠ¡API - OpenAIå…¼å®¹æ¥å£",
        "endpoints": [
            {"path": "/", "method": "GET", "description": "APIä¿¡æ¯"},
            {"path": "/v1/health", "method": "GET", "description": "å¥åº·æ£€æŸ¥"},
            {"path": "/v1/models", "method": "GET", "description": "æ¨¡å‹åˆ—è¡¨"},
            {"path": "/v1/chat/completions", "method": "POST", "description": "èŠå¤©æ¥å£ (OpenAIå…¼å®¹æ ¼å¼)"},
            {"path": "/v1/tools", "method": "POST", "description": "ç”¨æˆ·å·¥å…·ç®¡ç†æ¥å£"},
            {"path": "/v1/prompts", "method": "GET", "description": "æç¤ºæ¨¡æ¿åˆ—è¡¨"},
            {"path": "/v1/manage", "method": "POST", "description": "ç®¡ç†æ¥å£"},
            {"path": "/v1/prompts/get", "method": "POST", "description": "è·å–ç‰¹å®šæç¤ºæ¨¡æ¿"},
            {"path": "/v1/chat/predict", "method": "POST", "description": "é¢„æµ‹èŠå¤©"}
        ]
    })

async def health(_):
    """
    å¥åº·æ£€æŸ¥
    :return:  "healthy"
    """
    return JSONResponse({"status": "healthy"})

# åº”ç”¨é…ç½®
middleware = [
    Middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
]

async def startup_event():
    """
    å¯åŠ¨äº‹ä»¶
    """
    # é…ç½®æ—¥å¿—
    log_dir_path = pathlib.Path(__file__).parent / "logs"
    log_dir_path.mkdir(parents=True, exist_ok=True)
    log_file_path = log_dir_path / f"main_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.log"
    logger.add(log_file_path, rotation="100 MB")

    logger.info("===================== å¯åŠ¨äº‹ä»¶ ======================")
    logger.info(f"æ—¥å¿—ä¿å­˜ç›®å½•: {log_dir_path}")
    logger.info(f"MCPæœåŠ¡åœ°å€: {read_yaml_sse()}")

    # åˆå§‹åŒ–åŠ¨æ€å·¥å…·æ³¨å…¥ç³»ç»Ÿ
    try:
        from preserve_library.custom_tools.self_tools import initialize_dynamic_tool_injection_system
        logger.info("å¼€å§‹åˆå§‹åŒ–åŠ¨æ€å·¥å…·æ³¨å…¥ç³»ç»Ÿ...")

        initialization_result = await initialize_dynamic_tool_injection_system()

        if initialization_result["overall_status"] == "success":
            logger.info("âœ… åŠ¨æ€å·¥å…·æ³¨å…¥ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        elif initialization_result["overall_status"] == "partial_success":
            logger.warning(f"âš ï¸ åŠ¨æ€å·¥å…·æ³¨å…¥ç³»ç»Ÿéƒ¨åˆ†åˆå§‹åŒ–æˆåŠŸï¼Œå­˜åœ¨ {len(initialization_result['errors'])} ä¸ªé—®é¢˜")
            for error in initialization_result["errors"]:
                logger.warning(f"   - {error}")
        else:
            logger.error("âŒ åŠ¨æ€å·¥å…·æ³¨å…¥ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            for error in initialization_result["errors"]:
                logger.error(f"   - {error}")

    except Exception as e:
        logger.error(f"âŒ åŠ¨æ€å·¥å…·æ³¨å…¥ç³»ç»Ÿåˆå§‹åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        logger.error("åº”ç”¨å°†ç»§ç»­å¯åŠ¨ï¼Œä½†å·¥å…·æ³¨å…¥åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")

    # æ‰“å°æ‰€æœ‰å¯ç”¨çš„è·¯ç”±
    logger.info("å¯ç”¨çš„APIè·¯ç”±:")
    for route in app.routes:
        if isinstance(route, Route):
            logger.info(f"  {', '.join(route.methods)} {route.path}")
    logger.info("===================== å¯åŠ¨å®Œæˆ ======================")

async def manage(request: Request):
    """
    ç®¡ç†æ¥å£
    :method POST
    """
    pass

# åˆ›å»ºåº”ç”¨
app = Starlette(
    middleware=middleware,
    routes=[
        # æ ¹è·¯ç”±
        Route("/", root, methods=["GET"]),

        # è·¯ç”±
        Route("/v1/chat/completions", chat, methods=["POST"]),
        Route("/v1/chat/predict", predict, methods=["POST"]),
        Route("/v1/health", health, methods=["GET"]),
        Route("/v1/models", models, methods=["GET"]),

        # æç¤ºæ¨¡æ¿ç›¸å…³è·¯ç”±
        Route("/v1/prompts", list_prompts, methods=["GET"]),
        Route("/v1/prompts/get", get_prompt, methods=["POST"]),

        # äººç±»é‡‡æ ·ç›¸å…³è·¯ç”±
        Route("/v1/human-sampling", get_sample_interface, methods=["GET"]),
        Route("/v1/human-sampling/pending", get_pending_samples, methods=["GET"]),
        Route("/v1/human-sampling/respond", submit_sample_response, methods=["POST"]),

        # ç”¨æˆ·å·¥å…·ç›¸å…³è·¯ç”±
        Route("/v1/tools", agent_tools, methods=["POST"]),

        # ç®¡ç†ç›¸å…³è·¯ç”±
        Route("/v1/manage", manage, methods=["POST"])
    ],
    on_startup=[startup_event]
)

if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8030)
